{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os,sys\n",
    "import time\n",
    "import math\n",
    "sys.path.append('../..')\n",
    "#parametres \n",
    "data_set_name='gowalla'\n",
    "device='cuda:0'\n",
    "rerank_topk=20\n",
    "topk=20\n",
    "optimizer=lambda params: torch.optim.Adam(params, lr=1e-3, amsgrad=True)\n",
    "have_processed_data=True\n",
    "tree_num=4\n",
    "num_layers=1#layer of transformer\n",
    "k=18#the branch of each tree\n",
    "n_head=4\n",
    "d_model=96\n",
    "\n",
    "\n",
    "train_sample_seg_cnt=10#the training data is located in the train_sample_seg_cnt datafiles\n",
    "parall=10\n",
    "seq_len=70 # se_len-1 is the number of behaviours in all the windows\n",
    "min_seq_len=15\n",
    "test_user_num=1000# the number of user in test file\n",
    "raw_data_file='../../data/{}/{}.txt'.format(data_set_name,data_set_name)\n",
    "train_instances_file='../../data/{}/train_instances'.format(data_set_name)\n",
    "test_instances_file='../../data/{}/test_instances'.format(data_set_name)\n",
    "validation_instances_file='../../data/{}/validation_instances'.format(data_set_name)\n",
    "item_num_node_num_file='../../data/{}/item_node_num.txt'.format(data_set_name)\n",
    "train_item_vec_file='../../data/{}/train_item_vec.npy'.format(data_set_name)\n",
    "#item_to_code_file='../../data/{}/item_to_code.npy'.format(data_set_name)\n",
    "#code_to_item_file='../../data/{}/code_to_item.npy'.format(data_set_name)\n",
    "DIN_Model_path='../../data/{}/DIN_MODEL.pt'.format(data_set_name)\n",
    "tree_has_generated=True\n",
    "init_way='embkm'\n",
    "max_iters=100\n",
    "feature_ratio=1.0\n",
    "reranker=\"Trm\"\n",
    "total_batch_num=20000\n",
    "\n",
    "test_batch_size=50\n",
    "item_to_code_file_list=[]\n",
    "code_to_item_file_list=[]\n",
    "for tree_id in range(tree_num):\n",
    "    item_to_code_file='../../data/{}/tree/{}{}_item_to_code_tree_id_{}_k{}.npy'.format(data_set_name,init_way,feature_ratio,tree_id,k)\n",
    "    code_to_item_file='../../data/{}/tree/{}{}_code_to_item_tree_id_{}_k{}.npy'.format(data_set_name,init_way,feature_ratio,tree_id,k)\n",
    "    item_to_code_file_list.append(item_to_code_file)\n",
    "    code_to_item_file_list.append(code_to_item_file)\n",
    "#assert tree_num==1\n",
    "\n",
    "eps=0.000001\n",
    "if device!='cpu':\n",
    "    torch.cuda.set_device(device)\n",
    "    device='cuda'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from lib import Trm4Rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ##load DIN model which is the ranker for fine-ranking\n",
    "# from lib import DeepInterestNetwork as DIN\n",
    "# DIN_Model=torch.load(DIN_Model_path,map_location=torch.device(device))\n",
    "# DIN_Model.eval()\n",
    "# pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib\n",
    "from lib import generate_train_and_test_data\n",
    "import gc\n",
    "import numpy as np\n",
    "if not have_processed_data:\n",
    "    behavior_dict, train_sample, test_sample,validation_sample,user_num,item_num = _read(raw_data_file,test_user_num)  # 20 is the test users\n",
    "    # write the training instance into different train_sample_seg_cnt filesï¼Œ avoid that a file is too large\n",
    "    # stat record the click frequency of each item\n",
    "    # seq_len=20 min that 19 behaviors and one label\n",
    "    stat = _gen_train_sample(train_sample, train_instances_file,test_sample=test_sample,validation_sample=validation_sample,\n",
    "                                                    train_sample_seg_cnt=train_sample_seg_cnt,\n",
    "                                                    parall=parall, seq_len=seq_len, min_seq_len=min_seq_len)\n",
    "    _gen_test_sample(test_sample, test_instances_file, seq_len=seq_len,min_seq_len=min_seq_len)\n",
    "    _gen_test_sample(validation_sample, validation_instances_file, seq_len=seq_len,min_seq_len=min_seq_len)\n",
    "    del behavior_dict\n",
    "    del train_sample\n",
    "    del test_sample\n",
    "    del stat\n",
    "    #np.savetxt(item_num_node_num_file,np.array([user_num,item_num]),fmt='%d',delimiter=',')\n",
    "else:\n",
    "    [user_num,item_num]=np.loadtxt(item_num_node_num_file,dtype=np.int32,delimiter=',')\n",
    "print('user num is {}, item is {}'.format(user_num,item_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.generate_training_batches import Train_instance\n",
    "train_instances=Train_instance(parall=parall)\n",
    "#training_batch_generator=train_instances.training_batches(train_instances_file,train_sample_seg_cnt,item_num,batchsize=training_batch_size)\n",
    "training_data,training_labels=train_instances.get_training_data(train_instances_file,train_sample_seg_cnt,item_num)\n",
    "#test_batch_generator=train_instances.test_batches(test_instances_file,item_num,batchsize=test_batch_size)\n",
    "validation_batch_generator=train_instances.validation_batches(validation_instances_file,item_num,batchsize=test_batch_size)\n",
    "test_instances=train_instances.read_test_instances_file(test_instances_file,item_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "moving_average = lambda x, **kw: DataFrame({'x':np.asarray(x)}).x.ewm(**kw).mean().values\n",
    "loss_history,dev_precision_history,dev_recall_history,dev_f_measure_history,dev_novelty_history,policy_acc,dev_hr_history,dev_ndcg_history,dev_map_history=[],[],[],[],[],[],[],[],[]\n",
    "total_precision_history,total_recall_history,total_f_measure_history,total_novelty_history,total_hr_history,total_ndcg_history,total_map_history=[],[],[],[],[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def presision(result_list,gt_list,top_k):\n",
    "    count=0.0\n",
    "    for r,g in zip(result_list,gt_list):\n",
    "        count+=len(set(r).intersection(set(g)))\n",
    "    return count/(top_k*len(result_list))\n",
    "def recall(result_list,gt_list):\n",
    "    t=0.0\n",
    "    for r,g in zip(result_list,gt_list):\n",
    "        t+=1.0*len(set(r).intersection(set(g)))/len(g)\n",
    "    return t/len(result_list)\n",
    "def f_measure(result_list,gt_list,top_k,eps=1.0e-9):\n",
    "    f=0.0\n",
    "    for r,g in zip(result_list,gt_list):\n",
    "        recc=1.0*len(set(r).intersection(set(g)))/len(g)\n",
    "        pres=1.0*len(set(r).intersection(set(g)))/top_k\n",
    "        if recc+pres<eps:\n",
    "            continue\n",
    "        f+=(2*recc*pres)/(recc+pres)\n",
    "    return f/len(result_list)\n",
    "def novelty(result_list,s_u,top_k):\n",
    "    count=0.0\n",
    "    for r,g in zip(result_list,s_u):\n",
    "        count+=len(set(r)-set(g))\n",
    "    return count/(top_k*len(result_list))\n",
    "def hit_ratio(result_list,gt_list):\n",
    "    intersetct_set=[len(set(r)&set(g)) for r,g in zip(result_list,gt_list)]\n",
    "    return 1.0*sum(intersetct_set)/sum([len(gts) for gts in gt_list])\n",
    "\n",
    "def NDCG(result_list,gt_list):\n",
    "    t=0.0\n",
    "    for re,gt in zip(result_list,gt_list):\n",
    "        setgt=set(gt)\n",
    "        indicator=np.asfarray([1 if r in setgt else 0 for r in re])\n",
    "        sorted_indicator=indicator[indicator.argsort(-1)[::-1]]\n",
    "        if 1 in indicator:\n",
    "            t+=np.sum(indicator / np.log2(1.0*np.arange(2,len(indicator)+ 2)))/\\\n",
    "               np.sum(sorted_indicator/np.log2(1.0*np.arange(2,len(indicator)+ 2)))\n",
    "    return t/len(gt_list)\n",
    "\n",
    "def MAP(result_list,gt_list,topk):\n",
    "    t=0.0\n",
    "    for re,gt in zip(result_list,gt_list):\n",
    "        setgt=set(gt)\n",
    "        indicator=np.asfarray([1 if r in setgt else 0 for r in re])\n",
    "        t+=np.mean([indicator[:i].sum(-1)/i for i in range(1,topk+1)],axis=-1)\n",
    "    return t/len(gt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = None\n",
    "train_model_list = []\n",
    "for i in range(tree_num):\n",
    "    train_model = Trm4Rec(item_num=int(item_num),\n",
    "                          user_seq_len=seq_len-1,\n",
    "                          d_model=d_model,\n",
    "                          nhead=n_head,\n",
    "                          device=device,\n",
    "                          optimizer=optimizer,\n",
    "                          num_layers=num_layers,\n",
    "                          k=k,\n",
    "                          item_to_code_file=item_to_code_file_list[i],\n",
    "                          code_to_item_file=code_to_item_file_list[i],\n",
    "                          tree_has_generated=tree_has_generated,\n",
    "                          init_way=init_way,\n",
    "                          max_iters=max_iters,\n",
    "                          feature_ratio=feature_ratio,\n",
    "                          data=data,#used for kmeans tree\n",
    "                          parall=parall)\n",
    "    if i > 0:\n",
    "        train_model.trm_model.trm.encoder = train_model_list[0].trm_model.trm.encoder\n",
    "    train_model_list.append(train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file='../../data/{}/model/{}{}_model_encoder_k{}.pt'.format(data_set_name,init_way,feature_ratio,k)\n",
    "model_encoder = torch.load(model_file,map_location=torch.device(device))\n",
    "for tree_id in range(tree_num):\n",
    "    model_file='../../data/{}/model/{}{}_model_decoder_tree_id_{}_k{}.pt'.format(data_set_name,init_way,feature_ratio,tree_id,k)\n",
    "    train_model_list[tree_id].trm_model.trm.encoder = model_encoder\n",
    "    train_model_list[tree_id].trm_model.trm.decoder = torch.load(model_file,map_location=torch.device(device))\n",
    "    train_model_list[tree_id].trm_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = list(train_model_list[0].trm_model.trm.encoder.parameters())\n",
    "for i in range(tree_num):\n",
    "    model_parameters += list(train_model_list[i].trm_model.trm.decoder.parameters())\n",
    "model_optimizer = optimizer(model_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank(batch_x,label,top_k=rerank_topk,tree_num=11):\n",
    "    #all_time = 0\n",
    "    #start_time = time.time()\n",
    "    if tree_num == 1:\n",
    "        return label\n",
    "    #final_result=torch.full((len(batch_x),top_k),-1,dtype=torch.int64,device=device)\n",
    "    scores = torch.full((len(batch_x),top_k*tree_num),-1e15,device=device)\n",
    "    input_labels = torch.zeros((len(batch_x),top_k*tree_num),dtype=torch.int64,device=device)\n",
    "    max_lenr  = top_k\n",
    "    for i,user,result in zip(range(len(batch_x)),batch_x,label):\n",
    "        r=torch.LongTensor(list(set(result.tolist())))\n",
    "        scores[i,0:len(r)]=0.0\n",
    "        input_labels[i,0:len(r)]=r\n",
    "        max_lenr = max(max_lenr,len(r))\n",
    "    scores = scores[:,0:max_lenr]\n",
    "    input_labels = input_labels[:,0:max_lenr]\n",
    "    input_user = batch_x.repeat_interleave(max_lenr,dim=0)\n",
    "    input_item = input_labels.reshape(-1)\n",
    "    #all_time += time.time() - start_time\n",
    "    #print('all_time',all_time)\n",
    "    with torch.no_grad():\n",
    "        for j in range(tree_num):\n",
    "            #torch.cuda.empty_cache()\n",
    "            #time.sleep(0.5)\n",
    "            #start_time = time.time()\n",
    "            scores += train_model_list[j].compute_scores(\\\n",
    "                    input_user,\\\n",
    "                    input_item).sum(-1).view(batch_x.shape[0],-1)\n",
    "            #print(scores.shape,temp_scores.shape)\n",
    "            #scores = scores + temp_scores\n",
    "            #all_time += time.time()-start_time\n",
    "            #print('all_time',all_time)\n",
    "        #start_time = time.time()\n",
    "        argindex=scores.argsort(-1,True)[:,:top_k]\n",
    "        final_result=input_labels.gather(index=argindex,dim=-1)\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topk = 20\n",
    "for i in range(tree_num):\n",
    "    train_model_list[i].trm_model.eval()\n",
    "test_data = test_instances.to(device)\n",
    "batch_size = 50\n",
    "num_batch = math.ceil(test_data.shape[0]/batch_size)\n",
    "predict_time_list = []\n",
    "select_metric_list = []\n",
    "for select_tree_num in range(1,tree_num+1):    \n",
    "    print(select_tree_num)\n",
    "    for beam_size in [5,10,20,30,40,50,60,70,80,90,100]:\n",
    "        predict_time = 0\n",
    "        all_result = []\n",
    "        for j in range(num_batch):\n",
    "            batch_result_list = []\n",
    "            batch_user = test_data[j*batch_size:(j+1)*batch_size]\n",
    "            torch.cuda.empty_cache()\n",
    "            time.sleep(0.5)\n",
    "            for i in range(select_tree_num):\n",
    "                start_time = time.time()\n",
    "                batch_result = train_model_list[i].predict(batch_user,topk=topk,num_beams=beam_size)          \n",
    "                predict_time += time.time() - start_time\n",
    "                #print(predict_time)\n",
    "                torch.cuda.empty_cache()\n",
    "                time.sleep(0.5)\n",
    "                batch_result_list.append(batch_result)\n",
    "            #print(predict_time)\n",
    "            batch_result = torch.cat(batch_result_list,dim=-1)\n",
    "            start_time = time.time()\n",
    "            batch_result = rerank(batch_user,batch_result,rerank_topk,select_tree_num)\n",
    "            predict_time += time.time() - start_time\n",
    "            #print(time.time() - start_time)\n",
    "            #print(predict_time)\n",
    "            all_result.append(batch_result)\n",
    "        result_history = torch.cat(all_result,dim=0).cpu().numpy()\n",
    "        P = presision(result_history,train_instances.test_labels,rerank_topk)\n",
    "        R = recall(result_history,train_instances.test_labels)\n",
    "        F = f_measure(result_history,train_instances.test_labels,rerank_topk)\n",
    "        N = novelty(result_history,test_instances.tolist(),rerank_topk)\n",
    "        hr_= hit_ratio(result_history,train_instances.test_labels)\n",
    "        ndcg_ = NDCG(result_history,train_instances.test_labels)\n",
    "        map_ = MAP(result_history,train_instances.test_labels,rerank_topk)\n",
    "        select_metric_list.append([P,R,F,N,hr_,ndcg_,map_])\n",
    "        predict_time_list.append(predict_time)\n",
    "        print(\"beam_size = {}, time = {:.2f} : {:.4f}   {:.4f}   {:.4f}   {:.4f}   {:.4f}   {:.4f}   {:.4f}\".format(beam_size,predict_time_list[-1],P,R,F,N,hr_,ndcg_,map_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "41b01dbd54d66c6f96f9b705d522ef4a54c0bfab2c5953d35ea8ce7a0c7c1331"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
