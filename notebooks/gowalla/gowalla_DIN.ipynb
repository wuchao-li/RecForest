{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os,sys\n",
    "sys.path.append('../..')\n",
    "#parametres \n",
    "data_set_name='gowalla'\n",
    "device='cuda:0'\n",
    "topk=20\n",
    "optimizer=lambda params: torch.optim.Adam(params, lr=1e-3, amsgrad=True)\n",
    "have_processed_data=True\n",
    "\n",
    "emb_dim=96\n",
    "sum_pooling=False\n",
    "sample_negative_num=60\n",
    "feature_groups=[20,20,10,10,2,2,2,1,1,1]\n",
    "train_sample_seg_cnt=10#the training data is located in the train_sample_seg_cnt datafiles\n",
    "parall=10\n",
    "seq_len=70 # se_len-1 is the number of behaviours in all the windows\n",
    "min_seq_len=15\n",
    "test_user_num=6000# the number of user in test file\n",
    "raw_data_file='../../data/{}/{}.txt'.format(data_set_name,data_set_name)\n",
    "train_instances_file='../../data/{}/train_instances'.format(data_set_name)\n",
    "test_instances_file='../../data/{}/test_instances'.format(data_set_name)\n",
    "validation_instances_file='../../data/{}/validation_instances'.format(data_set_name)\n",
    "item_num_node_num_file='../../data/{}/item_node_num.txt'.format(data_set_name)\n",
    "\n",
    "\n",
    "\n",
    "test_batch_size=100\n",
    "\n",
    "batch_number=80000#\n",
    "if device!='cpu':\n",
    "    torch.cuda.set_device(device)\n",
    "    device='cuda'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib\n",
    "from lib import generate_train_and_test_data\n",
    "import gc\n",
    "import numpy as np\n",
    "if not have_processed_data: \n",
    "    behavior_dict, train_sample, test_sample ,user_num,item_num,item_vec= generate_train_and_test_data._read(raw_data_file, 'train.dat', 'test.dat',\n",
    "                                                                            test_user_num)  # 20 is the test users\n",
    "    # write the training instance into different train_sample_seg_cnt filesï¼Œ avoid that a file is too large\n",
    "    # stat record the click frequency of each item\n",
    "    # seq_len=20 min that 19 behaviors and one label\n",
    "    stat = generate_train_and_test_data._gen_train_sample(train_sample, train_instances_file,test_sample=test_sample,\n",
    "                                                    train_sample_seg_cnt=train_sample_seg_cnt,\n",
    "                                                    parall=parall, seq_len=seq_len, min_seq_len=min_seq_len)\n",
    "    generate_train_and_test_data._gen_test_sample(test_sample, test_instances_file, seq_len=seq_len,\n",
    "                                            min_seq_len=min_seq_len)\n",
    "    del behavior_dict\n",
    "    del train_sample\n",
    "    del test_sample\n",
    "    del stat\n",
    "    np.savetxt(item_num_node_num_file,np.array([user_num,item_num]),fmt='%d',delimiter=',')\n",
    "else:\n",
    "    [user_num,item_num]=np.loadtxt(item_num_node_num_file,dtype=np.int32,delimiter=',')\n",
    "print('user num is {}, item is {}'.format(user_num,item_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import DINTrain\n",
    "\n",
    "train_model=DINTrain(item_num=item_num,\n",
    "                     sample_negative_num=sample_negative_num,\n",
    "                     emb_dim=emb_dim,\n",
    "                     device=device,\n",
    "                     sum_pooling=sum_pooling,\n",
    "                     feature_groups=feature_groups,\n",
    "                     optimizer=optimizer)\n",
    "print(train_model.DINModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lib.generate_training_batches import Train_instance\n",
    "train_instances=Train_instance(parall=parall)\n",
    "#training_batch_generator=train_instances.training_batches(train_instances_file,train_sample_seg_cnt,item_num,batchsize=training_batch_size)\n",
    "training_data,training_labels=train_instances.get_training_data(train_instances_file,train_sample_seg_cnt,item_num)\n",
    "#test_batch_generator=train_instances.test_batches(test_instances_file,item_num,batchsize=test_batch_size)\n",
    "validation_batch_generator=train_instances.validation_batches(validation_instances_file,item_num,batchsize=test_batch_size)\n",
    "test_instances=train_instances.read_test_instances_file(test_instances_file,item_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "moving_average = lambda x, **kw: DataFrame({'x':np.asarray(x)}).x.ewm(**kw).mean().values\n",
    "loss_history,dev_precision_history,dev_recall_history,dev_f_measure_history,dev_novelty_history,policy_acc=[],[],[],[],[],[]\n",
    "total_precision_history,total_recall_history,total_f_measure_history,total_novelty_history=[],[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def presision(result_list,gt_list,top_k):\n",
    "    count=0.0\n",
    "    for r,g in zip(result_list,gt_list):\n",
    "        count+=len(set(r).intersection(set(g)))\n",
    "    return count/(top_k*len(result_list))\n",
    "def recall(result_list,gt_list):\n",
    "    t=0.0\n",
    "    for r,g in zip(result_list,gt_list):\n",
    "        t+=1.0*len(set(r).intersection(set(g)))/len(g)\n",
    "    return t/len(result_list)\n",
    "def f_measure(result_list,gt_list,top_k,eps=1.0e-9):\n",
    "    f=0.0\n",
    "    for r,g in zip(result_list,gt_list):\n",
    "        recc=1.0*len(set(r).intersection(set(g)))/len(g)\n",
    "        pres=1.0*len(set(r).intersection(set(g)))/top_k\n",
    "        if recc+pres<eps:\n",
    "            continue\n",
    "        f+=(2*recc*pres)/(recc+pres)\n",
    "    return f/len(result_list)\n",
    "def novelty(result_list,s_u,top_k):\n",
    "    count=0.0\n",
    "    for r,g in zip(result_list,s_u):\n",
    "        count+=len(set(r)-set(g))\n",
    "    return count/(top_k*len(result_list))\n",
    "def hit_ratio(result_list,gt_list):\n",
    "    intersetct_set=[len(set(r)&set(g)) for r,g in zip(result_list,gt_list)]\n",
    "    return 1.0*sum(intersetct_set)/sum([len(gts) for gts in gt_list])\n",
    "\n",
    "def NDCG(result_list,gt_list):\n",
    "    t=0.0\n",
    "    for re,gt in zip(result_list,gt_list):\n",
    "        setgt=set(gt)\n",
    "        indicator=np.asfarray([1 if r in setgt else 0 for r in re])\n",
    "        sorted_indicator=indicator[indicator.argsort(-1)[::-1]]\n",
    "        if 1 in indicator:\n",
    "            t+=np.sum(indicator / np.log2(1.0*np.arange(2,len(indicator)+ 2)))/\\\n",
    "               np.sum(sorted_indicator/np.log2(1.0*np.arange(2,len(indicator)+ 2)))\n",
    "    return t/len(gt_list)\n",
    "\n",
    "def MAP(result_list,gt_list,topk):\n",
    "    t=0.0\n",
    "    for re,gt in zip(result_list,gt_list):\n",
    "        setgt=set(gt)\n",
    "        indicator=np.asfarray([1 if r in setgt else 0 for r in re])\n",
    "        t+=np.mean([indicator[:i].sum(-1)/i for i in range(1,topk+1)],axis=-1)\n",
    "    return t/len(gt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_model.DINModel.train()\n",
    "validation_batch_generator=train_instances.validation_batches(validation_instances_file,item_num,batchsize=test_batch_size)\n",
    "for (batch_x,batch_y) in train_instances.generate_training_records(training_data,training_labels,batch_size=256):\n",
    "    #print(batch_x,batch_y)\n",
    "    loss=train_model.update_DIN(batch_x,batch_y)\n",
    "    loss_history.append(loss.item())\n",
    "    \n",
    "    if train_model.batch_num%5000==0:\n",
    "        # train_model.DINModel.eval()\n",
    "        # resutl_history=train_model.predict(test_instances,topk=topk).numpy()#40 is N\n",
    "        # total_precision_history.append(presision(resutl_history,train_instances.test_labels,topk))\n",
    "        # total_recall_history.append(recall(resutl_history,train_instances.test_labels))\n",
    "        # total_f_measure_history.append(f_measure(resutl_history,train_instances.test_labels,topk))\n",
    "        # total_novelty_history.append(novelty(resutl_history,test_instances.tolist(),topk))\n",
    "        # train_model.DINModel.train()\n",
    "\n",
    "        # ###start to test\n",
    "        train_model.DINModel.eval()\n",
    "        test_batch,test_index=validation_batch_generator.__next__()\n",
    "        gt_history=[train_instances.validation_labels[i.item()] for i in test_index]\n",
    "\n",
    "        all_items=torch.arange(item_num,device=device).view(-1,1)\n",
    "        preference_matrix=torch.full((len(test_batch),item_num),-1.0e9,dtype=torch.float32)\n",
    "        batch_size=2000\n",
    "        f_num=test_batch.shape[1]\n",
    "        #print(item_num,test_batch.shape)\n",
    "        for i,user in enumerate(test_batch):\n",
    "            start_id=0\n",
    "            while start_id<item_num:\n",
    "                part_labels=all_items[start_id:start_id+batch_size,:]\n",
    "                #print(len(part_labels),)\n",
    "                with torch.no_grad():\n",
    "                    preference_matrix[i,start_id:start_id+batch_size]=train_model.calculate_preference(\\\n",
    "                        user.to(device).expand(len(part_labels),f_num),part_labels).view(1,-1).cpu()\n",
    "                start_id=start_id+batch_size\n",
    "        resutl_history=preference_matrix.argsort(dim=-1)[:,-topk:].numpy()\n",
    "        total_precision_history.append(presision(resutl_history,gt_history,topk))\n",
    "        total_recall_history.append(recall(resutl_history,gt_history))\n",
    "        total_f_measure_history.append(f_measure(resutl_history,gt_history,topk))\n",
    "        total_novelty_history.append(novelty(resutl_history,test_batch.tolist(),topk))\n",
    "        train_model.DINModel.train()\n",
    "        # #######\n",
    "\n",
    "\n",
    "            \n",
    "    if train_model.batch_num% 100 == 0:\n",
    "        \n",
    "        # ###start to test\n",
    "        # train_model.DINModel.eval()\n",
    "        # test_batch,test_index=validation_batch_generator.__next__()\n",
    "        # gt_history=[train_instances.validation_labels[i.item()] for i in test_index]\n",
    "        # resutl_history=train_model.predict(test_batch,topk=topk).numpy()\n",
    "        # dev_precision_history.append(presision(resutl_history,gt_history,topk))\n",
    "        # dev_recall_history.append(recall(resutl_history,gt_history))\n",
    "        # dev_f_measure_history.append(f_measure(resutl_history,gt_history,topk))\n",
    "        # dev_novelty_history.append(novelty(resutl_history,test_batch.tolist(),topk))\n",
    "        # train_model.DINModel.train()\n",
    "        # #######\n",
    "            \n",
    "\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=[18, 12])\n",
    "        plt.subplot(2, 3, 1)\n",
    "        plt.title('train loss over time'); plt.grid();\n",
    "        plt.plot(moving_average(loss_history, span=50))\n",
    "        plt.scatter(range(len(loss_history)), loss_history, alpha=0.1)\n",
    "\n",
    "        plt.subplot(2, 3, 2)\n",
    "        plt.title('dev presision over time'); plt.grid();\n",
    "        # plt.plot(moving_average(dev_precision_history, span=50))\n",
    "        # plt.scatter(range(len(dev_precision_history)), dev_precision_history, alpha=0.1)\n",
    "        plt.plot(50*(np.arange(len(total_precision_history)) + 1), total_precision_history, c='r')\n",
    "        \n",
    "        plt.subplot(2, 3, 3)\n",
    "        plt.title('dev recall over time'); plt.grid();\n",
    "        # plt.plot(moving_average(dev_recall_history, span=10))\n",
    "        # plt.scatter(range(len(dev_recall_history)), dev_recall_history, alpha=0.1)\n",
    "        plt.plot(50*(np.arange(len(total_recall_history)) + 1), total_recall_history, c='r')\n",
    "        \n",
    "        plt.subplot(2, 3, 4)\n",
    "        plt.title('dev f-measure over time'); plt.grid();\n",
    "        # plt.plot(moving_average(dev_f_measure_history, span=10))\n",
    "        # plt.scatter(range(len(dev_f_measure_history)), dev_f_measure_history, alpha=0.1)\n",
    "        plt.plot(50*(np.arange(len(total_f_measure_history)) + 1), total_f_measure_history, c='r')\n",
    "        \n",
    "        plt.subplot(2, 3, 5)\n",
    "        plt.title('dev novelty over time'); plt.grid();\n",
    "        # plt.plot(moving_average(dev_novelty_history, span=10))\n",
    "        # plt.scatter(range(len(dev_novelty_history)), dev_novelty_history, alpha=0.1)\n",
    "        plt.plot(50*(np.arange(len(total_novelty_history)) + 1), total_novelty_history, c='r')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        print(\"step=%i, mean_loss=%.3f, time=%.3f\" % \n",
    "              (len(loss_history), np.mean(loss_history[-100:]),1.0))\n",
    "        print('_' * 100)\n",
    "    \n",
    "    if train_model.batch_num>batch_number:\n",
    "        break\n",
    "        '''\n",
    "        np.savetxt(result_prefix+\"prob_loss.txt\",np.array(loss_history),fmt='%f')\n",
    "        np.savetxt(result_prefix+\"prob_policy_acc.txt\",np.array(policy_acc),fmt='%f')\n",
    "        \n",
    "        np.savetxt(result_prefix+\"prob_dev_precision.txt\",np.array(dev_precision_history),fmt='%f')\n",
    "        np.savetxt(result_prefix+\"prob_total_precision.txt\",np.array(total_precision_history),fmt='%f')\n",
    "        \n",
    "        np.savetxt(result_prefix+\"prob_dev_recall.txt\",np.array(dev_recall_history),fmt='%f')\n",
    "        np.savetxt(result_prefix+\"prob_total_recall.txt\",np.array(total_recall_history),fmt='%f')\n",
    "        \n",
    "        np.savetxt(result_prefix+\"prob_dev_f_measure.txt\",np.array(dev_f_measure_history),fmt='%f')\n",
    "        np.savetxt(result_prefix+\"prob_total_f_measure.txt\",np.array(total_f_measure_history),fmt='%f')\n",
    "        \n",
    "        np.savetxt(result_prefix+\"prob_dev_novelty.txt\",np.array(dev_novelty_history),fmt='%f')\n",
    "        np.savetxt(result_prefix+\"prob_total_novelty.txt\",np.array(total_novelty_history),fmt='%f')\n",
    "        '''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_model.DINModel.eval()\n",
    "# resutl_history=train_model.predict(test_instances,topk=topk).numpy()#40 is N\n",
    "# total_precision_history.append(presision(resutl_history,train_instances.test_labels,topk))\n",
    "# total_recall_history.append(recall(resutl_history,train_instances.test_labels))\n",
    "# total_f_measure_history.append(f_measure(resutl_history,train_instances.test_labels,topk))\n",
    "# total_novelty_history.append(novelty(resutl_history,test_instances.tolist(),topk))\n",
    "# train_model.DINModel.train()\n",
    "\n",
    "\n",
    "train_model.DINModel.eval()\n",
    "gt_history=train_instances.test_labels\n",
    "all_items=torch.arange(item_num,device=device).view(-1,1)\n",
    "preference_matrix=torch.full((len(test_instances),item_num),-1.0e9,dtype=torch.float32)\n",
    "batch_size=2000\n",
    "f_num=test_instances.shape[1]\n",
    "#print(item_num,test_batch.shape)\n",
    "for i,user in enumerate(test_instances):\n",
    "    start_id=0\n",
    "    while start_id<item_num:\n",
    "        part_labels=all_items[start_id:start_id+batch_size,:]\n",
    "        #print(len(part_labels),)\n",
    "        with torch.no_grad():\n",
    "            preference_matrix[i,start_id:start_id+batch_size]=train_model.calculate_preference(\\\n",
    "                user.to(device).expand(len(part_labels),f_num),part_labels).view(1,-1).cpu()\n",
    "        start_id=start_id+batch_size\n",
    "resutl_history=preference_matrix.argsort(dim=-1)[:,-topk:].numpy()\n",
    "total_precision_history.append(presision(resutl_history,gt_history,topk))\n",
    "total_recall_history.append(recall(resutl_history,gt_history))\n",
    "total_f_measure_history.append(f_measure(resutl_history,gt_history,topk))\n",
    "total_novelty_history.append(novelty(resutl_history,test_batch.tolist(),topk))\n",
    "train_model.DINModel.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIN_Model_path='../../data/{}/DIN_MODEL.pt'.format(data_set_name)\n",
    "torch.save(train_model.DINModel,DIN_Model_path)\n",
    "print(total_precision_history[-1],total_recall_history[-1],total_f_measure_history[-1],total_novelty_history[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_test_users_path='../../data/{}/sorted_test_users.txt'.format(data_set_name)\n",
    "np.savetxt(sorted_test_users_path,preference_matrix.argsort(dim=-1).numpy(),delimiter=',',fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def presision(result_list,gt_list,top_k):\n",
    "    count=0.0\n",
    "    for r,g in zip(result_list,gt_list):\n",
    "        count+=len(set(r).intersection(set(g)))\n",
    "    return count/(top_k*len(result_list))\n",
    "def recall(result_list,gt_list):\n",
    "    t=0.0\n",
    "    for r,g in zip(result_list,gt_list):\n",
    "        t+=1.0*len(set(r).intersection(set(g)))/len(g)\n",
    "    return t/len(result_list)\n",
    "def f_measure(result_list,gt_list,top_k,eps=1.0e-9):\n",
    "    f=0.0\n",
    "    for r,g in zip(result_list,gt_list):\n",
    "        recc=1.0*len(set(r).intersection(set(g)))/len(g)\n",
    "        pres=1.0*len(set(r).intersection(set(g)))/top_k\n",
    "        if recc+pres<eps:\n",
    "            continue\n",
    "        f+=(2*recc*pres)/(recc+pres)\n",
    "    return f/len(result_list)\n",
    "def novelty(result_list,s_u,top_k):\n",
    "    count=0.0\n",
    "    for r,g in zip(result_list,s_u):\n",
    "        count+=len(set(r)-set(g))\n",
    "    return count/(top_k*len(result_list))\n",
    "def hit_ratio(result_list,gt_list):\n",
    "    intersetct_set=[len(set(r)&set(g)) for r,g in zip(result_list,gt_list)]\n",
    "    return 1.0*sum(intersetct_set)/sum([len(gts) for gts in gt_list])\n",
    "\n",
    "def NDCG(result_list,gt_list):\n",
    "    t=0.0\n",
    "    for re,gt in zip(result_list,gt_list):\n",
    "        setgt=set(gt)\n",
    "        indicator=np.asfarray([1 if r in setgt else 0 for r in re])\n",
    "        sorted_indicator=indicator[indicator.argsort(-1)[::-1]]\n",
    "        if 1 in indicator:\n",
    "            t+=np.sum(indicator / np.log2(1.0*np.arange(2,len(indicator)+ 2)))/\\\n",
    "               np.sum(sorted_indicator/np.log2(1.0*np.arange(2,len(indicator)+ 2)))\n",
    "    return t/len(gt_list)\n",
    "\n",
    "def MAP(result_list,gt_list,topk):\n",
    "    t=0.0\n",
    "    for re,gt in zip(result_list,gt_list):\n",
    "        setgt=set(gt)\n",
    "        indicator=np.asfarray([1 if r in setgt else 0 for r in re])\n",
    "        t+=np.mean([indicator[:i].sum(-1)/i for i in range(1,topk+1)],axis=-1)\n",
    "    return t/len(gt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.generate_training_batches import Train_instance\n",
    "train_instances=Train_instance(parall=parall)\n",
    "test_instances=train_instances.read_test_instances_file(test_instances_file,item_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_test_users_path='../../data/{}/sorted_test_users.txt'.format(data_set_name)\n",
    "gt_history=train_instances.test_labels\n",
    "preference_matrix=np.loadtxt(sorted_test_users_path,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk=40\n",
    "resutl_history=np.array(preference_matrix[:,-1:-topk-1:-1],dtype=np.int32)\n",
    "P = presision(resutl_history,gt_history,topk)\n",
    "R = recall(resutl_history,gt_history)\n",
    "F = f_measure(resutl_history,gt_history,topk)\n",
    "N = novelty(resutl_history,test_instances.tolist(),topk)\n",
    "hr_ = hit_ratio(resutl_history,gt_history)\n",
    "ndcg_ = NDCG(resutl_history,gt_history)\n",
    "map_ = MAP(resutl_history,gt_history,topk)\n",
    "print(\"{:.4f}   {:.4f}   {:.4f}   {:.4f}   {:.4f}   {:.4f}   {:.4f}\".format(P,R,F,N,hr_,ndcg_,map_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(preference_matrix,dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b92dc86a37ed12f9dcbd1566d51a12cb028a66fbf4deae5bf9fb8af5b0029ae"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
