{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os,sys\n",
    "import time\n",
    "import math\n",
    "sys.path.append('../..')\n",
    "#parametres \n",
    "data_set_name='gowalla'\n",
    "device='cuda:4'\n",
    "rerank_topk=20\n",
    "topk=20\n",
    "optimizer=lambda params: torch.optim.Adam(params, lr=1e-3, amsgrad=True)\n",
    "have_processed_data=True\n",
    "tree_num=4\n",
    "num_layers=1#layer of transformer\n",
    "k=18#the branch of each tree\n",
    "n_head=4\n",
    "d_model=96\n",
    "\n",
    "\n",
    "train_sample_seg_cnt=10#the training data is located in the train_sample_seg_cnt datafiles\n",
    "parall=10\n",
    "seq_len=70 # se_len-1 is the number of behaviours in all the windows\n",
    "min_seq_len=15\n",
    "test_user_num=1000# the number of user in test file\n",
    "raw_data_file='../../data/{}/{}.txt'.format(data_set_name,data_set_name)\n",
    "train_instances_file='../../data/{}/train_instances'.format(data_set_name)\n",
    "test_instances_file='../../data/{}/test_instances'.format(data_set_name)\n",
    "validation_instances_file='../../data/{}/validation_instances'.format(data_set_name)\n",
    "item_num_node_num_file='../../data/{}/item_node_num.txt'.format(data_set_name)\n",
    "train_item_vec_file='../../data/{}/train_item_vec.npy'.format(data_set_name)\n",
    "#item_to_code_file='../../data/{}/item_to_code.npy'.format(data_set_name)\n",
    "#code_to_item_file='../../data/{}/code_to_item.npy'.format(data_set_name)\n",
    "DIN_Model_path='../../data/{}/DIN_MODEL.pt'.format(data_set_name)\n",
    "tree_has_generated=True\n",
    "init_way='embkm'\n",
    "max_iters=100\n",
    "feature_ratio=1.0\n",
    "reranker=\"Trm\"\n",
    "total_batch_num=20000\n",
    "\n",
    "test_batch_size=50\n",
    "item_to_code_file_list=[]\n",
    "code_to_item_file_list=[]\n",
    "for tree_id in range(tree_num):\n",
    "    item_to_code_file='../../data/{}/tree/{}{}_item_to_code_tree_id_{}_k{}.npy'.format(data_set_name,init_way,feature_ratio,tree_id,k)\n",
    "    code_to_item_file='../../data/{}/tree/{}{}_code_to_item_tree_id_{}_k{}.npy'.format(data_set_name,init_way,feature_ratio,tree_id,k)\n",
    "    item_to_code_file_list.append(item_to_code_file)\n",
    "    code_to_item_file_list.append(code_to_item_file)\n",
    "#assert tree_num==1\n",
    "\n",
    "eps=0.000001\n",
    "if device!='cpu':\n",
    "    torch.cuda.set_device(device)\n",
    "    device='cuda'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from lib import Trm4Rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ##load DIN model which is the ranker for fine-ranking\n",
    "# from lib import DeepInterestNetwork as DIN\n",
    "# DIN_Model=torch.load(DIN_Model_path,map_location=torch.device(device))\n",
    "# DIN_Model.eval()\n",
    "# pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib\n",
    "from lib import generate_train_and_test_data\n",
    "import gc\n",
    "import numpy as np\n",
    "if not have_processed_data:\n",
    "    behavior_dict, train_sample, test_sample,validation_sample,user_num,item_num = _read(raw_data_file,test_user_num)  # 20 is the test users\n",
    "    # write the training instance into different train_sample_seg_cnt filesï¼Œ avoid that a file is too large\n",
    "    # stat record the click frequency of each item\n",
    "    # seq_len=20 min that 19 behaviors and one label\n",
    "    stat = _gen_train_sample(train_sample, train_instances_file,test_sample=test_sample,validation_sample=validation_sample,\n",
    "                                                    train_sample_seg_cnt=train_sample_seg_cnt,\n",
    "                                                    parall=parall, seq_len=seq_len, min_seq_len=min_seq_len)\n",
    "    _gen_test_sample(test_sample, test_instances_file, seq_len=seq_len,min_seq_len=min_seq_len)\n",
    "    _gen_test_sample(validation_sample, validation_instances_file, seq_len=seq_len,min_seq_len=min_seq_len)\n",
    "    del behavior_dict\n",
    "    del train_sample\n",
    "    del test_sample\n",
    "    del stat\n",
    "    #np.savetxt(item_num_node_num_file,np.array([user_num,item_num]),fmt='%d',delimiter=',')\n",
    "else:\n",
    "    [user_num,item_num]=np.loadtxt(item_num_node_num_file,dtype=np.int32,delimiter=',')\n",
    "print('user num is {}, item is {}'.format(user_num,item_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.generate_training_batches import Train_instance\n",
    "train_instances=Train_instance(parall=parall)\n",
    "#training_batch_generator=train_instances.training_batches(train_instances_file,train_sample_seg_cnt,item_num,batchsize=training_batch_size)\n",
    "training_data,training_labels=train_instances.get_training_data(train_instances_file,train_sample_seg_cnt,item_num)\n",
    "#test_batch_generator=train_instances.test_batches(test_instances_file,item_num,batchsize=test_batch_size)\n",
    "validation_batch_generator=train_instances.validation_batches(validation_instances_file,item_num,batchsize=test_batch_size)\n",
    "test_instances=train_instances.read_test_instances_file(test_instances_file,item_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "moving_average = lambda x, **kw: DataFrame({'x':np.asarray(x)}).x.ewm(**kw).mean().values\n",
    "loss_history,dev_precision_history,dev_recall_history,dev_f_measure_history,dev_novelty_history,policy_acc,dev_hr_history,dev_ndcg_history,dev_map_history=[],[],[],[],[],[],[],[],[]\n",
    "total_precision_history,total_recall_history,total_f_measure_history,total_novelty_history,total_hr_history,total_ndcg_history,total_map_history=[],[],[],[],[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def presision(result_list,gt_list,top_k):\n",
    "    count=0.0\n",
    "    for r,g in zip(result_list,gt_list):\n",
    "        count+=len(set(r).intersection(set(g)))\n",
    "    return count/(top_k*len(result_list))\n",
    "def recall(result_list,gt_list):\n",
    "    t=0.0\n",
    "    for r,g in zip(result_list,gt_list):\n",
    "        t+=1.0*len(set(r).intersection(set(g)))/len(g)\n",
    "    return t/len(result_list)\n",
    "def f_measure(result_list,gt_list,top_k,eps=1.0e-9):\n",
    "    f=0.0\n",
    "    for r,g in zip(result_list,gt_list):\n",
    "        recc=1.0*len(set(r).intersection(set(g)))/len(g)\n",
    "        pres=1.0*len(set(r).intersection(set(g)))/top_k\n",
    "        if recc+pres<eps:\n",
    "            continue\n",
    "        f+=(2*recc*pres)/(recc+pres)\n",
    "    return f/len(result_list)\n",
    "def novelty(result_list,s_u,top_k):\n",
    "    count=0.0\n",
    "    for r,g in zip(result_list,s_u):\n",
    "        count+=len(set(r)-set(g))\n",
    "    return count/(top_k*len(result_list))\n",
    "def hit_ratio(result_list,gt_list):\n",
    "    intersetct_set=[len(set(r)&set(g)) for r,g in zip(result_list,gt_list)]\n",
    "    return 1.0*sum(intersetct_set)/sum([len(gts) for gts in gt_list])\n",
    "\n",
    "def NDCG(result_list,gt_list):\n",
    "    t=0.0\n",
    "    for re,gt in zip(result_list,gt_list):\n",
    "        setgt=set(gt)\n",
    "        indicator=np.asfarray([1 if r in setgt else 0 for r in re])\n",
    "        sorted_indicator = np.ones(min(len(setgt), len(re)))\n",
    "        if 1 in indicator:\n",
    "            t+=np.sum(indicator / np.log2(1.0*np.arange(2,len(indicator)+ 2)))/\\\n",
    "               np.sum(sorted_indicator/np.log2(1.0*np.arange(2,len(sorted_indicator)+ 2)))\n",
    "    return t/len(gt_list)\n",
    "\n",
    "def MAP(result_list,gt_list,topk):\n",
    "    t=0.0\n",
    "    for re,gt in zip(result_list,gt_list):\n",
    "        setgt=set(gt)\n",
    "        indicator=np.asfarray([1 if r in setgt else 0 for r in re])\n",
    "        t+=np.mean([indicator[:i].sum(-1)/i for i in range(1,topk+1)],axis=-1)\n",
    "    return t/len(gt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = DIN_Model.item_embedding.embed.weight.data[:item_num,:].cpu()\n",
    "data = None\n",
    "train_model_list = []\n",
    "for i in range(tree_num):\n",
    "    train_model = Trm4Rec(item_num=int(item_num),\n",
    "                          user_seq_len=seq_len-1,\n",
    "                          d_model=d_model,\n",
    "                          nhead=n_head,\n",
    "                          device=device,\n",
    "                          optimizer=optimizer,\n",
    "                          num_layers=num_layers,\n",
    "                          k=k,\n",
    "                          item_to_code_file=item_to_code_file_list[i],\n",
    "                          code_to_item_file=code_to_item_file_list[i],\n",
    "                          tree_has_generated=tree_has_generated,\n",
    "                          init_way=init_way,\n",
    "                          max_iters=max_iters,\n",
    "                          feature_ratio=feature_ratio,\n",
    "                          data=data,#used for kmeans tree\n",
    "                          parall=parall)\n",
    "    if i > 0:\n",
    "        train_model.trm_model.trm.encoder = train_model_list[0].trm_model.trm.encoder\n",
    "    train_model_list.append(train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_file='../../data/{}/model/{}{}_model_encoder_k{}.pt'.format(data_set_name,init_way,feature_ratio,k)\n",
    "# model_encoder = torch.load(model_file,map_location=torch.device(device))\n",
    "# for tree_id in range(tree_num):\n",
    "#     model_file='../../data/{}/model/{}{}_model_decoder_tree_id_{}_k{}.pt'.format(data_set_name,init_way,feature_ratio,tree_id,k)\n",
    "#     train_model_list[tree_id].trm_model.trm.encoder = model_encoder\n",
    "#     train_model_list[tree_id].trm_model.trm.decoder = torch.load(model_file,map_location=torch.device(device))\n",
    "#     train_model_list[tree_id].trm_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = list(train_model_list[0].trm_model.trm.encoder.parameters())\n",
    "for i in range(tree_num):\n",
    "    model_parameters += list(train_model_list[i].trm_model.trm.decoder.parameters())\n",
    "model_optimizer = optimizer(model_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank(batch_x,label,top_k=rerank_topk,tree_num=11):\n",
    "    #all_time = 0\n",
    "    #start_time = time.time()\n",
    "    if tree_num == 1:\n",
    "        return label\n",
    "    #final_result=torch.full((len(batch_x),top_k),-1,dtype=torch.int64,device=device)\n",
    "    scores = torch.full((len(batch_x),top_k*tree_num),-1e15,device=device)\n",
    "    input_labels = torch.zeros((len(batch_x),top_k*tree_num),dtype=torch.int64,device=device)\n",
    "    max_lenr  = top_k\n",
    "    for i,user,result in zip(range(len(batch_x)),batch_x,label):\n",
    "        r=torch.LongTensor(list(set(result.tolist())))\n",
    "        scores[i,0:len(r)]=0.0\n",
    "        input_labels[i,0:len(r)]=r\n",
    "        max_lenr = max(max_lenr,len(r))\n",
    "    scores = scores[:,0:max_lenr]\n",
    "    input_labels = input_labels[:,0:max_lenr]\n",
    "    input_user = batch_x.repeat_interleave(max_lenr,dim=0)\n",
    "    input_item = input_labels.reshape(-1)\n",
    "    #all_time += time.time() - start_time\n",
    "    #print('all_time',all_time)\n",
    "    with torch.no_grad():\n",
    "        for j in range(tree_num):\n",
    "            #torch.cuda.empty_cache()\n",
    "            #time.sleep(0.5)\n",
    "            #start_time = time.time()\n",
    "            scores += train_model_list[j].compute_scores(\\\n",
    "                    input_user,\\\n",
    "                    input_item).sum(-1).view(batch_x.shape[0],-1)\n",
    "            #print(scores.shape,temp_scores.shape)\n",
    "            #scores = scores + temp_scores\n",
    "            #all_time += time.time()-start_time\n",
    "            #print('all_time',all_time)\n",
    "        #start_time = time.time()\n",
    "        argindex=scores.argsort(-1,True)[:,:top_k]\n",
    "        final_result=input_labels.gather(index=argindex,dim=-1)\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_batch = math.ceil(test_instances.shape[0]/test_batch_size)\n",
    "for i in range(tree_num):\n",
    "    train_model_list[i].trm_model.train()\n",
    "validation_batch_generator=train_instances.validation_batches(validation_instances_file,item_num,batchsize=test_batch_size)\n",
    "for (batch_x,batch_y) in train_instances.generate_training_records(training_data,training_labels,batch_size=256):\n",
    "    #print(batch_x,batch_y)\n",
    "    #loss=train_model.update_model(batch_x,batch_y)\n",
    "    loss = 0\n",
    "    for i in range(tree_num):\n",
    "        loss+=train_model_list[i].update_model(batch_x,batch_y)\n",
    "    loss.backward()\n",
    "    model_optimizer.step()\n",
    "    model_optimizer.zero_grad()\n",
    "    loss_history.append(loss.item())\n",
    "    if train_model_list[0].batch_num%5000==0:\n",
    "        #train_model.trm_model.eval()\n",
    "        for i in range(tree_num):\n",
    "            train_model_list[i].trm_model.eval()\n",
    "        #result_history=train_model.predict(test_instances,topk=topk).numpy()\n",
    "        result_history=[]\n",
    "        for j in range(num_batch):\n",
    "            batch_result_list = []\n",
    "            batch_user = test_instances[j*test_batch_size:(j+1)*test_batch_size].to(device)\n",
    "            for i in range(tree_num):\n",
    "                batch_result_one_tree = train_model_list[i].predict(batch_user,topk=topk)          \n",
    "                batch_result_list.append(batch_result_one_tree)\n",
    "            batch_result = torch.cat(batch_result_list,dim=-1)\n",
    "            batch_result = rerank(batch_user,batch_result,rerank_topk,tree_num)\n",
    "            result_history.append(batch_result)\n",
    "        result_history = torch.cat(result_history,dim=0).cpu().numpy()\n",
    "        total_precision_history.append(presision(result_history,train_instances.test_labels,rerank_topk))\n",
    "        total_recall_history.append(recall(result_history,train_instances.test_labels))\n",
    "        total_f_measure_history.append(f_measure(result_history,train_instances.test_labels,rerank_topk))\n",
    "        total_novelty_history.append(novelty(result_history,test_instances.tolist(),rerank_topk))\n",
    "        total_hr_history.append(hit_ratio(result_history,train_instances.test_labels))\n",
    "        total_ndcg_history.append(NDCG(result_history,train_instances.test_labels))\n",
    "        total_map_history.append(MAP(result_history,train_instances.test_labels,rerank_topk))\n",
    "\n",
    "        #train_model.trm_model.train()\n",
    "        for i in range(tree_num):\n",
    "            train_model_list[i].trm_model.train()\n",
    "\n",
    "\n",
    "            \n",
    "    if train_model_list[0].batch_num% 100 == 0:\n",
    "        \n",
    "        ###start to test\n",
    "        #train_model.trm_model.eval()\n",
    "        for i in range(tree_num):\n",
    "            train_model_list[i].trm_model.eval()\n",
    "        test_batch,test_index=validation_batch_generator.__next__()\n",
    "        test_batch = test_batch.to(device)\n",
    "        gt_history=[train_instances.validation_labels[i.item()] for i in test_index]\n",
    "        #result_history=train_model.predict(test_batch,topk=topk).numpy()\n",
    "        result_history=[]\n",
    "        for i in range(tree_num):\n",
    "            result_history.append(train_model_list[i].predict(test_batch,topk=topk))\n",
    "        result_history = rerank(test_batch, torch.cat(result_history,dim=-1),tree_num=tree_num).cpu().numpy()\n",
    "        dev_precision_history.append(presision(result_history,gt_history,rerank_topk))\n",
    "        dev_recall_history.append(recall(result_history,gt_history))\n",
    "        dev_f_measure_history.append(f_measure(result_history,gt_history,rerank_topk))\n",
    "        dev_novelty_history.append(novelty(result_history,test_batch.tolist(),rerank_topk))\n",
    "        dev_hr_history.append(hit_ratio(result_history,gt_history))\n",
    "        dev_ndcg_history.append(NDCG(result_history,gt_history))\n",
    "        dev_map_history.append(MAP(result_history,gt_history,rerank_topk))\n",
    "        for i in range(tree_num):\n",
    "            train_model_list[i].trm_model.train()\n",
    "            \n",
    "\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=[18, 12])\n",
    "        plt.subplot(2, 3, 1)\n",
    "        plt.title('train loss over time'); plt.grid();\n",
    "        plt.plot(moving_average(loss_history, span=50))\n",
    "        plt.scatter(range(len(loss_history)), loss_history, alpha=0.1)\n",
    "\n",
    "        plt.subplot(2, 3, 2)\n",
    "        plt.title('dev presision over time'); plt.grid();\n",
    "        plt.plot(moving_average(dev_precision_history, span=50))\n",
    "        plt.scatter(range(len(dev_precision_history)), dev_precision_history, alpha=0.1)\n",
    "        plt.plot(50*(np.arange(len(total_precision_history)) + 1), total_precision_history, c='r')\n",
    "        \n",
    "        plt.subplot(2, 3, 3)\n",
    "        plt.title('dev recall over time'); plt.grid();\n",
    "        plt.plot(moving_average(dev_recall_history, span=10))\n",
    "        plt.scatter(range(len(dev_recall_history)), dev_recall_history, alpha=0.1)\n",
    "        plt.plot(50*(np.arange(len(total_recall_history)) + 1), total_recall_history, c='r')\n",
    "        \n",
    "        plt.subplot(2, 3, 4)\n",
    "        plt.title('dev f-measure over time'); plt.grid();\n",
    "        plt.plot(moving_average(dev_f_measure_history, span=10))\n",
    "        plt.scatter(range(len(dev_f_measure_history)), dev_f_measure_history, alpha=0.1)\n",
    "        plt.plot(50*(np.arange(len(total_f_measure_history)) + 1), total_f_measure_history, c='r')\n",
    "        \n",
    "        plt.subplot(2, 3, 5)\n",
    "        plt.title('dev novelty over time'); plt.grid();\n",
    "        plt.plot(moving_average(dev_novelty_history, span=10))\n",
    "        plt.scatter(range(len(dev_novelty_history)), dev_novelty_history, alpha=0.1)\n",
    "        plt.plot(50*(np.arange(len(total_novelty_history)) + 1), total_novelty_history, c='r')\n",
    "        \n",
    "        plt.subplot(2, 3, 6)\n",
    "        plt.title('dev ndcg over time'); plt.grid();\n",
    "        plt.plot(moving_average(dev_ndcg_history, span=10))\n",
    "        plt.scatter(range(len(dev_ndcg_history)), dev_ndcg_history, alpha=0.1)\n",
    "        plt.plot(50*(np.arange(len(total_ndcg_history)) + 1), total_ndcg_history, c='r')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        print(\"step=%i, mean_loss=%.3f, time=%.3f\" % \n",
    "              (len(loss_history), np.mean(loss_history[-100:]),1.0))\n",
    "        print('_' * 100)\n",
    "    if train_model_list[0].batch_num > total_batch_num:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_file='../../data/{}/model/{}{}_model_encoder_k{}.pt'.format(data_set_name,init_way,feature_ratio,k)\n",
    "# torch.save(train_model_list[0].trm_model.trm.encoder,model_file)\n",
    "# for tree_id in range(tree_num):\n",
    "#     model_file='../../data/{}/model/{}{}_model_decoder_tree_id_{}_k{}.pt'.format(data_set_name,init_way,feature_ratio,tree_id,k)\n",
    "#     torch.save(train_model_list[tree_id].trm_model.trm.decoder,model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "41b01dbd54d66c6f96f9b705d522ef4a54c0bfab2c5953d35ea8ce7a0c7c1331"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
